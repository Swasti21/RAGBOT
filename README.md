
ğŸ“š Multi-PDF Chat Agent ğŸ¤–

Meet Multi-PDF Chat AI App! ğŸš€ Chat seamlessly with multiple PDFs using LangChain, Google Gemini, HuggingFace embeddings & FAISS Vector DB, all wrapped in a clean Streamlit UI.

Get fast, accurate, natural answers from your documents â€” ask questions in plain language, and the AI finds + explains the answer from your PDFs. ğŸ”¥âœ¨

â¸»

ğŸ“ Description

The Multi-PDF Chat Agent is a Streamlit-based web application that allows you to:
	â€¢	Upload multiple PDF documents.
	â€¢	Automatically extract and chunk text.
	â€¢	Build a searchable FAISS vector index.
	â€¢	Ask questions in real-time and get evidence-based answers.

Think of it as ChatGPT for your documents.

â¸»

ğŸ“Š Demo (Optional for Now)

âš¡ Soon youâ€™ll be able to deploy this with Streamlit Cloud or Hugging Face Spaces.

â¸»

ğŸ¯ How It Works

	1.	PDF Loading â†’ Extracts raw text from your uploaded PDFs.
	2.	Text Chunking â†’ Splits into small sections so AI can handle them efficiently.
	3.	Embeddings â†’ Uses HuggingFace embeddings (all-MiniLM-L6-v2) to vectorize text.
	4.	Vector DB (FAISS) â†’ Stores embeddings for fast similarity search.
	5.	LLM (Gemini) â†’ Generates answers by combining retrieved evidence with generative reasoning.

â¸»

ğŸš€ Features
	â€¢	âœ… Multi-PDF conversational QA
	â€¢	âœ… HuggingFace embeddings (free, unlimited, no API quota issues)
	â€¢	âœ… Google Gemini LLM (powerful, contextual answers)
	â€¢	âœ… Natural, ChatGPT-like responses (not JSON blobs)
	â€¢	âœ… Evidence view â†’ See where the answer came from
	â€¢	âœ… Streamlit UI with polished design

â¸»

âš™ï¸ Requirements
	â€¢	streamlit â€“ interactive web UI
	â€¢	google-generativeai â€“ Gemini integration
	â€¢	python-dotenv â€“ load environment variables
	â€¢	langchain + langchain-community â€“ RAG pipelines
	â€¢	PyPDF2 â€“ PDF text extraction
	â€¢	faiss-cpu â€“ vector database
	â€¢	sentence-transformers â€“ HuggingFace embeddings
	â€¢	langchain-google-genai â€“ Gemini LLM wrapper

â¸»

â–¶ï¸ Installation

Clone the repo:

git clone https://github.com/Adityism/Ragbot.git
cd Ragbot

Install dependencies:

pip install -r requirements.txt

Set up your .env with your Gemini API key:

GOOGLE_API_KEY=<your-api-key>

Run the app:

streamlit run chatapp.py


â¸»

ğŸ’¡ Usage
	1.	Upload one or more PDFs in the sidebar.
	2.	Click Build Index to process them.
	3.	Ask any question in plain English.
	4.	Get answers + evidence directly from your docs.

â¸»

ğŸ“ Project Structure

Ragbot/
â”œâ”€â”€ RAG-BOT/               # Core app directory
â”‚   â”œâ”€â”€ docs/              # Your uploaded PDFs
â”‚   â”œâ”€â”€ faiss_index/       # Vector DB storage
â”‚   â””â”€â”€ chatapp.py         # Main Streamlit app
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                   # Your API key
â””â”€â”€ README.md


â¸»

ğŸªª License

Distributed under the MIT License. See LICENSE for details.

â¸»

â­ Support

If you like this project:
	â€¢	Drop a â­ on the repo â†’ Adityism/Ragbot
	â€¢	Connect with me:
	â€¢	LinkedIn
	â€¢	GitHub

